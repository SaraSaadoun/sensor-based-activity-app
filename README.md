# Motion Detection System using mobile sensorsğŸš€

This project is a **real-time motion classification system** that collects **accelerometer** and **gyroscope** sensor data from a **React Native app** and uses a **Flask-based API with a deep learning model** for activity classification.  

---

## ğŸ“Œ Features
- ğŸ“¡ **Real-time motion detection** using mobile sensors.
- ğŸ“± **React Native mobile app** to collect sensor data.
- ğŸ§  **Deep learning model** for activity classification.
- ğŸŒ **Flask-based API** for prediction.
- ğŸ“Š **Displays prediction results dynamically**.

---

## ğŸ“· Preview
![sensor](https://github.com/user-attachments/assets/0c4a00dc-d08e-4a7e-9417-98d9905b639c)

---

## ğŸ› ï¸ Technologies Used
### **Backend (Flask)**
### **Frontend (React Native)**

---

## âš™ï¸ How It Works
### **Mobile App (React Native)**
1. Collects **accelerometer** and **gyroscope** data using `expo-sensors`.
2. Stores **the last 150 readings** from both sensors.
3. Sends the collected data to the Flask backend for classification.
4. Displays the **predicted activity** in real-time.

### **Backend (Flask)**
1. Receives **sensor data** from the mobile app.
2. Preprocesses and reshapes the data for input to the model.
3. Uses a **trained deep learning model** (`latest_motion_detection_model.h5`) to predict activity.
4. Sends back the **predicted motion** (e.g., *sitting, jogging, walking*) as a response.
---

